{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn import svm\n",
    "# from sklearn import tree\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Prototype_data_DL.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   File  label   1   2   3   4  5  6   7   8\n",
       "0     1      0   0   0   0   0  0  2   1  26\n",
       "1     2      0   0   0   0   0  2  1  16  34\n",
       "2     3      1   0   0   6   2  1  4   7   8\n",
       "3     4      1  31  32  33  36  2  1   1  26\n",
       "4     5      0  36   2   1   2  1  2   1   8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0,0,0,0,0,2,1,26]\n",
    "l2 = [0,0,0,0,2,1,16,34]\n",
    "l3 = [0,0,6,2,1,4,7,8]\n",
    "l4 = [31,32,33,36,2,1,1,26]\n",
    "l5 = [36,2,1,2,1,2,1,8]\n",
    "l6 = [0,0,0,0,0,0,2,1]\n",
    "l7 = [0,0,0,0,2,1,16,34]\n",
    "l8 = [0,36,2,1,1,4,7,8]\n",
    "l9 = [31,2,1,2,2,1,1,26]\n",
    "l10 = [36,2,1,2,1,2,1,8]\n",
    "sequences = []\n",
    "sequences.append(l1)\n",
    "sequences.append(l2)\n",
    "sequences.append(l3)\n",
    "sequences.append(l4)\n",
    "sequences.append(l5)\n",
    "sequences.append(l6)\n",
    "sequences.append(l7)\n",
    "sequences.append(l8)\n",
    "sequences.append(l9)\n",
    "sequences.append(l10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 2, 1, 26],\n",
       " [0, 0, 0, 0, 2, 1, 16, 34],\n",
       " [0, 0, 6, 2, 1, 4, 7, 8],\n",
       " [31, 32, 33, 36, 2, 1, 1, 26],\n",
       " [36, 2, 1, 2, 1, 2, 1, 8],\n",
       " [0, 0, 0, 0, 0, 0, 2, 1],\n",
       " [0, 0, 0, 0, 2, 1, 16, 34],\n",
       " [0, 36, 2, 1, 1, 4, 7, 8],\n",
       " [31, 2, 1, 2, 2, 1, 1, 26],\n",
       " [36, 2, 1, 2, 1, 2, 1, 8]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequences[:5]\n",
    "y_train = data.iloc[:5, 1].values\n",
    "X_test = sequences[5:]\n",
    "y_test = data.iloc[5:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 2, 1],\n",
       " [0, 0, 0, 0, 2, 1, 16, 34],\n",
       " [0, 36, 2, 1, 1, 4, 7, 8],\n",
       " [31, 2, 1, 2, 2, 1, 1, 26],\n",
       " [36, 2, 1, 2, 1, 2, 1, 8]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(x, y=None, batch_size=2):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x= x[:n_batches*batch_size]\n",
    "    if y is not None:\n",
    "        y = y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        if y is not None:\n",
    "            yield x[ii:ii+batch_size], y[ii:ii+batch_size]\n",
    "        else:\n",
    "            yield x[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzeLogRNN(object):\n",
    "    def __init__(self, n_words, seq_len=8,\n",
    "                 lstm_size=256, num_layers=2, batch_size=5,\n",
    "                 learning_rate=0.0001, embed_size=8):\n",
    "        self.n_words = n_words\n",
    "        self.seq_len = seq_len\n",
    "        self.lstm_size = lstm_size \n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            tf.set_random_seed(123)\n",
    "            self.build()\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "    def build(self):\n",
    "        tf_x = tf.placeholder(tf.int32,\n",
    "                              shape=(self.batch_size, self.seq_len),\n",
    "                              name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.float32,\n",
    "                              shape=(self.batch_size),\n",
    "                              name='tf_y')\n",
    "        tf_keepprob = tf.placeholder(tf.float32,\n",
    "                                     name='tf_keepprob')\n",
    "        \n",
    "        embedding = tf.Variable(\n",
    "            tf.random_uniform(\n",
    "                (self.n_words, self.embed_size),\n",
    "                minval=-1, maxval=1),\n",
    "            name='embedding')\n",
    "        embed_x = tf.nn.embedding_lookup(\n",
    "            embedding, tf_x,\n",
    "            name='embeded_x')\n",
    "\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(\n",
    "            [tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(self.lstm_size),\n",
    "                output_keep_prob=tf_keepprob)\n",
    "                for i in range(self.num_layers)])\n",
    "\n",
    "        self.initial_state = cells.zero_state(\n",
    "            self.batch_size, tf.float32)\n",
    "        print('  << initial state >> ', self.initial_state)\n",
    "\n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "            cells, embed_x,\n",
    "            initial_state=self.initial_state)\n",
    "        \n",
    "        print('\\n  << lstm_output   >> ', lstm_outputs)\n",
    "        print('\\n  << final state   >> ', self.final_state)\n",
    "\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=lstm_outputs[:, -1],\n",
    "            units=1, activation=None,\n",
    "            name='logits')\n",
    "\n",
    "        logits = tf.squeeze(logits, name='logits_squeezed')\n",
    "        print ('\\n  << logits        >> ', logits)\n",
    "\n",
    "        y_proba = tf.nn.sigmoid(logits, name='probabilities')\n",
    "        predictions = {\n",
    "            'probabilities': y_proba,\n",
    "            'labels' : tf.cast(tf.round(y_proba), tf.int32,\n",
    "                               name='labels')\n",
    "        }\n",
    "        print('\\n  << predictions   >> ', predictions)\n",
    "\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf_y, logits=logits),\n",
    "            name='cost')\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train_op = optimizer.minimize(cost, name='train_op')\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs):\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            sess.run(self.init_op)\n",
    "            iteration = 1\n",
    "            for epoch in range(num_epochs):\n",
    "                state = sess.run(self.initial_state)\n",
    "\n",
    "                for batch_x, batch_y in create_batch_generator(\n",
    "                        X_train, y_train, self.batch_size):\n",
    "                    feed = {'tf_x:0': batch_x,\n",
    "                            'tf_y:0': batch_y,\n",
    "                            'tf_keepprob:0': 0.5,\n",
    "                            self.initial_state : state}\n",
    "                    loss, _, state = sess.run(\n",
    "                        ['cost:0', 'train_op',\n",
    "                         self.final_state],\n",
    "                        feed_dict=feed)\n",
    "\n",
    "                    if iteration % 20 == 0:\n",
    "                        print(\"Epoch: %d/%d Iteration: %d \"\n",
    "                              \"| Train loss: %.5f\" % (\n",
    "                                  epoch + 1, num_epochs,\n",
    "                                  iteration, loss))\n",
    "\n",
    "                    iteration +=1\n",
    "                if (epoch+1)%10 == 0:\n",
    "                    self.saver.save(sess,\n",
    "                                    \"model/sentiment-%d.ckpt\" % epoch)\n",
    "\n",
    "    def predict(self, X_data, return_proba=False):\n",
    "        preds = []\n",
    "        with tf.Session(graph = self.g) as sess:\n",
    "            self.saver.restore(\n",
    "                sess, tf.train.latest_checkpoint('model/'))\n",
    "            test_state = sess.run(self.initial_state)\n",
    "            for ii, batch_x in enumerate(\n",
    "                    create_batch_generator(\n",
    "                        X_data, None, batch_size=self.batch_size), 1):\n",
    "                feed = {'tf_x:0' : batch_x,\n",
    "                        'tf_keepprob:0': 1.0,\n",
    "                        self.initial_state : test_state}\n",
    "                if return_proba:\n",
    "                    pred, test_state = sess.run(\n",
    "                        ['probabilities:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "                else:\n",
    "                    pred, test_state = sess.run(\n",
    "                        ['labels:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "\n",
    "                preds.append(pred)\n",
    "\n",
    "        return np.concatenate(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 42\n",
    "sequence_length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  << initial state >>  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(5, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(5, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros:0' shape=(5, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros_1:0' shape=(5, 256) dtype=float32>))\n",
      "\n",
      "  << lstm_output   >>  Tensor(\"rnn/transpose_1:0\", shape=(5, 8, 256), dtype=float32)\n",
      "\n",
      "  << final state   >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(5, 256) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(5, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_5:0' shape=(5, 256) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_6:0' shape=(5, 256) dtype=float32>))\n",
      "\n",
      "  << logits        >>  Tensor(\"logits_squeezed:0\", shape=(5,), dtype=float32)\n",
      "\n",
      "  << predictions   >>  {'probabilities': <tf.Tensor 'probabilities:0' shape=(5,) dtype=float32>, 'labels': <tf.Tensor 'labels:0' shape=(5,) dtype=int32>}\n"
     ]
    }
   ],
   "source": [
    "rnn = AnalyzeLogRNN(n_words=n_words,\n",
    "                   seq_len=sequence_length,\n",
    "                   embed_size=8,\n",
    "                   lstm_size=256,\n",
    "                   num_layers=2,\n",
    "                   batch_size=5,\n",
    "                   learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.train(X_train, y_train, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/sentiment-9.ckpt\n"
     ]
    }
   ],
   "source": [
    "proba = rnn.predict(X_test, return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.61865808e-05,   4.46955266e-04,   9.54227805e-01,\n",
       "         9.91116881e-01,   9.91954267e-01], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/sentiment-9.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rnn.predict(X_test)\n",
    "pred #predicted by RNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test # Actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label: 1 - success, 0 - failure\n",
    "#So the test data had three failures and two success logs\n",
    "#RNN LSTM model predicted both successes correctly, it predicted two out of three failures correctly and \n",
    "# misclassified one as success"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
