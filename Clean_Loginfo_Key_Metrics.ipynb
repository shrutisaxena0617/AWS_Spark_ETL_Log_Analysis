{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is Exploratory Data Analysis for Key Metrics on the Logs\n",
    "\n",
    "The exploration will follow the following steps:\n",
    "1. Load test and training dataset and necessary python packages\n",
    "\n",
    "2. Convert data in the three memory columns into analyzable form\n",
    "\n",
    "3. Convert \"NA\" into null value\n",
    "\n",
    "4. Export a cleaned csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Load dataset and necessary python packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "logs = pd.read_csv('C:/Users/Mengyu/Desktop/study/Auto Desk/log_extraction/Spark_ETL_Loginfo_Key_Metrics_transformed_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. Convert data in the three memory columns to analyzable form **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log File</th>\n",
       "      <th>state_accept_epoch</th>\n",
       "      <th>state_running_time</th>\n",
       "      <th>state_running_epoch</th>\n",
       "      <th>waiting_time_to_run</th>\n",
       "      <th>spark_driver_start_time</th>\n",
       "      <th>spark_driver_start_time_epoch</th>\n",
       "      <th>spark_driver_memory</th>\n",
       "      <th>spark_executor_memory</th>\n",
       "      <th>memoryStore_capacity</th>\n",
       "      <th>job_result</th>\n",
       "      <th>job_successfully_completed_at_time</th>\n",
       "      <th>job_successfully_completed_at_time_epoch</th>\n",
       "      <th>job_failed_at_time</th>\n",
       "      <th>job_failed_at_time_epoch</th>\n",
       "      <th>waiting_time_to_accept</th>\n",
       "      <th>successful_job_completion_time</th>\n",
       "      <th>failed_job_completion_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application_1513303661803_25646_asrd.cp.big.da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1983.0MB</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application_1513303661803_23926_asrd.cp.big.da...</td>\n",
       "      <td>1.513792e+09</td>\n",
       "      <td>17/12/20 17:52:06</td>\n",
       "      <td>1513792326</td>\n",
       "      <td>6</td>\n",
       "      <td>17/12/20 17:51:57</td>\n",
       "      <td>1513792317</td>\n",
       "      <td>12g</td>\n",
       "      <td>6144M</td>\n",
       "      <td>8.4GB</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/20 17:58:04</td>\n",
       "      <td>1513792684</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application_1513303661803_21767_asrd.cp.big.da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>143.6MB</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application_1513303661803_24558_asrd.cp.big.da...</td>\n",
       "      <td>1.513814e+09</td>\n",
       "      <td>17/12/21 00:01:41</td>\n",
       "      <td>1513814501</td>\n",
       "      <td>5</td>\n",
       "      <td>17/12/21 00:01:33</td>\n",
       "      <td>1513814493</td>\n",
       "      <td>8G</td>\n",
       "      <td>15G</td>\n",
       "      <td>5.5GB</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/21 00:21:10</td>\n",
       "      <td>1513815670</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3</td>\n",
       "      <td>1169</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application_1513303661803_24282_asrd.cp.big.da...</td>\n",
       "      <td>1.513797e+09</td>\n",
       "      <td>17/12/20 19:05:06</td>\n",
       "      <td>1513796706</td>\n",
       "      <td>9</td>\n",
       "      <td>17/12/20 19:04:52</td>\n",
       "      <td>1513796692</td>\n",
       "      <td>12G</td>\n",
       "      <td>16G</td>\n",
       "      <td>8.4GB</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/20 19:14:03</td>\n",
       "      <td>1513797243</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>537</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Log File  state_accept_epoch  \\\n",
       "0  application_1513303661803_25646_asrd.cp.big.da...                 NaN   \n",
       "1  application_1513303661803_23926_asrd.cp.big.da...        1.513792e+09   \n",
       "2  application_1513303661803_21767_asrd.cp.big.da...                 NaN   \n",
       "3  application_1513303661803_24558_asrd.cp.big.da...        1.513814e+09   \n",
       "4  application_1513303661803_24282_asrd.cp.big.da...        1.513797e+09   \n",
       "\n",
       "   state_running_time state_running_epoch waiting_time_to_run  \\\n",
       "0                  NA                  NA                  NA   \n",
       "1   17/12/20 17:52:06          1513792326                   6   \n",
       "2                  NA                  NA                  NA   \n",
       "3   17/12/21 00:01:41          1513814501                   5   \n",
       "4   17/12/20 19:05:06          1513796706                   9   \n",
       "\n",
       "  spark_driver_start_time spark_driver_start_time_epoch spark_driver_memory  \\\n",
       "0                      NA                            NA                  NA   \n",
       "1       17/12/20 17:51:57                    1513792317                 12g   \n",
       "2                      NA                            NA                  NA   \n",
       "3       17/12/21 00:01:33                    1513814493                  8G   \n",
       "4       17/12/20 19:04:52                    1513796692                 12G   \n",
       "\n",
       "  spark_executor_memory memoryStore_capacity                   job_result  \\\n",
       "0                    NA             1983.0MB                           NA   \n",
       "1                 6144M                8.4GB   Job completed successfully   \n",
       "2                    NA              143.6MB                           NA   \n",
       "3                   15G                5.5GB   Job completed successfully   \n",
       "4                   16G                8.4GB   Job completed successfully   \n",
       "\n",
       "  job_successfully_completed_at_time job_successfully_completed_at_time_epoch  \\\n",
       "0                                 NA                                       NA   \n",
       "1                  17/12/20 17:58:04                               1513792684   \n",
       "2                                 NA                                       NA   \n",
       "3                  17/12/21 00:21:10                               1513815670   \n",
       "4                  17/12/20 19:14:03                               1513797243   \n",
       "\n",
       "  job_failed_at_time job_failed_at_time_epoch waiting_time_to_accept  \\\n",
       "0                 NA                       NA                     NA   \n",
       "1                 NA                       NA                      3   \n",
       "2                 NA                       NA                     NA   \n",
       "3                 NA                       NA                      3   \n",
       "4                 NA                       NA                      5   \n",
       "\n",
       "  successful_job_completion_time failed_job_completion_time  \n",
       "0                             NA                         NA  \n",
       "1                            358                         NA  \n",
       "2                             NA                         NA  \n",
       "3                           1169                         NA  \n",
       "4                            537                         NA  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataset\n",
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g    324\n",
      "G    175\n",
      "M     44\n",
      "Name: 1, dtype: int64\n",
      "G    292\n",
      "M    251\n",
      "Name: 1, dtype: int64\n",
      "GB    875\n",
      "MB    156\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to check all kinds of formats of Megabyte and Gigabyte\n",
    "print(logs['spark_driver_memory'].str.extract('(.*\\d)(\\w*)', expand=True)[1].value_counts())\n",
    "print(logs['spark_executor_memory'].str.extract('(.*\\d)(\\w*)', expand=True)[1].value_counts())\n",
    "print(logs['memoryStore_capacity'].str.extract('(.*\\d)(\\w*)', expand=True)[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert all Gigabyte into Megabyte\n",
    "def GBtoMB(df):\n",
    "    df = df.copy()\n",
    "    num = df.str.extract('(.*\\d)(\\w*)', expand=True)[0]\n",
    "    unit = df.str.extract('(.*\\d)(\\w*)', expand=True)[1]\n",
    "    ifGB = unit.isin(['GB','G','g'])\n",
    "    df[ifGB] = round(num[ifGB].astype(float)*1024,1)\n",
    "    ifMB = unit.isin(['MB','M'])\n",
    "    df[ifMB] = round(num[ifMB].astype(float),1)\n",
    "    return df\n",
    "\n",
    "logs['spark_driver_memory'] = GBtoMB(logs['spark_driver_memory']).replace('NA','')\n",
    "logs['spark_executor_memory'] = GBtoMB(logs['spark_executor_memory'])\n",
    "logs['memoryStore_capacity'] = GBtoMB(logs['memoryStore_capacity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename changed memory columns\n",
    "name_change = {'spark_driver_memory':'spark_driver_memory_MB', 'spark_executor_memory':'spark_executor_memory_MB', 'memoryStore_capacity':'memoryStore_capacity_MB'}\n",
    "logs = logs.rename(columns = name_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spark_driver_memory_MB</th>\n",
       "      <th>spark_executor_memory_MB</th>\n",
       "      <th>memoryStore_capacity_MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12288</td>\n",
       "      <td>6144</td>\n",
       "      <td>8601.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>143.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8192</td>\n",
       "      <td>15360</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12288</td>\n",
       "      <td>16384</td>\n",
       "      <td>8601.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  spark_driver_memory_MB spark_executor_memory_MB memoryStore_capacity_MB\n",
       "0                     NA                       NA                    1983\n",
       "1                  12288                     6144                  8601.6\n",
       "2                     NA                       NA                   143.6\n",
       "3                   8192                    15360                    5632\n",
       "4                  12288                    16384                  8601.6"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display changed memory columns\n",
    "logs[['spark_driver_memory_MB','spark_executor_memory_MB','memoryStore_capacity_MB']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Convert \"NA\" into null value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " NA                            516\n",
       " Job completed successfully    511\n",
       " Job failed                     30\n",
       "Name: job_result, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display value count of job result\n",
    "logs['job_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log File</th>\n",
       "      <th>state_accept_epoch</th>\n",
       "      <th>state_running_time</th>\n",
       "      <th>state_running_epoch</th>\n",
       "      <th>waiting_time_to_run</th>\n",
       "      <th>spark_driver_start_time</th>\n",
       "      <th>spark_driver_start_time_epoch</th>\n",
       "      <th>spark_driver_memory_MB</th>\n",
       "      <th>spark_executor_memory_MB</th>\n",
       "      <th>memoryStore_capacity_MB</th>\n",
       "      <th>job_result</th>\n",
       "      <th>job_successfully_completed_at_time</th>\n",
       "      <th>job_successfully_completed_at_time_epoch</th>\n",
       "      <th>job_failed_at_time</th>\n",
       "      <th>job_failed_at_time_epoch</th>\n",
       "      <th>waiting_time_to_accept</th>\n",
       "      <th>successful_job_completion_time</th>\n",
       "      <th>failed_job_completion_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application_1513303661803_25646_asrd.cp.big.da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application_1513303661803_23926_asrd.cp.big.da...</td>\n",
       "      <td>1.513792e+09</td>\n",
       "      <td>17/12/20 17:52:06</td>\n",
       "      <td>1513792326</td>\n",
       "      <td>6</td>\n",
       "      <td>17/12/20 17:51:57</td>\n",
       "      <td>1513792317</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>8601.6</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/20 17:58:04</td>\n",
       "      <td>1513792684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application_1513303661803_21767_asrd.cp.big.da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application_1513303661803_24558_asrd.cp.big.da...</td>\n",
       "      <td>1.513814e+09</td>\n",
       "      <td>17/12/21 00:01:41</td>\n",
       "      <td>1513814501</td>\n",
       "      <td>5</td>\n",
       "      <td>17/12/21 00:01:33</td>\n",
       "      <td>1513814493</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/21 00:21:10</td>\n",
       "      <td>1513815670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application_1513303661803_24282_asrd.cp.big.da...</td>\n",
       "      <td>1.513797e+09</td>\n",
       "      <td>17/12/20 19:05:06</td>\n",
       "      <td>1513796706</td>\n",
       "      <td>9</td>\n",
       "      <td>17/12/20 19:04:52</td>\n",
       "      <td>1513796692</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>8601.6</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>17/12/20 19:14:03</td>\n",
       "      <td>1513797243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Log File  state_accept_epoch  \\\n",
       "0  application_1513303661803_25646_asrd.cp.big.da...                 NaN   \n",
       "1  application_1513303661803_23926_asrd.cp.big.da...        1.513792e+09   \n",
       "2  application_1513303661803_21767_asrd.cp.big.da...                 NaN   \n",
       "3  application_1513303661803_24558_asrd.cp.big.da...        1.513814e+09   \n",
       "4  application_1513303661803_24282_asrd.cp.big.da...        1.513797e+09   \n",
       "\n",
       "   state_running_time state_running_epoch waiting_time_to_run  \\\n",
       "0                 NaN                 NaN                 NaN   \n",
       "1   17/12/20 17:52:06          1513792326                   6   \n",
       "2                 NaN                 NaN                 NaN   \n",
       "3   17/12/21 00:01:41          1513814501                   5   \n",
       "4   17/12/20 19:05:06          1513796706                   9   \n",
       "\n",
       "  spark_driver_start_time spark_driver_start_time_epoch  \\\n",
       "0                     NaN                           NaN   \n",
       "1       17/12/20 17:51:57                    1513792317   \n",
       "2                     NaN                           NaN   \n",
       "3       17/12/21 00:01:33                    1513814493   \n",
       "4       17/12/20 19:04:52                    1513796692   \n",
       "\n",
       "   spark_driver_memory_MB  spark_executor_memory_MB  memoryStore_capacity_MB  \\\n",
       "0                     NaN                       NaN                   1983.0   \n",
       "1                 12288.0                    6144.0                   8601.6   \n",
       "2                     NaN                       NaN                    143.6   \n",
       "3                  8192.0                   15360.0                   5632.0   \n",
       "4                 12288.0                   16384.0                   8601.6   \n",
       "\n",
       "                    job_result job_successfully_completed_at_time  \\\n",
       "0                          NaN                                NaN   \n",
       "1   Job completed successfully                  17/12/20 17:58:04   \n",
       "2                          NaN                                NaN   \n",
       "3   Job completed successfully                  17/12/21 00:21:10   \n",
       "4   Job completed successfully                  17/12/20 19:14:03   \n",
       "\n",
       "  job_successfully_completed_at_time_epoch job_failed_at_time  \\\n",
       "0                                      NaN                NaN   \n",
       "1                               1513792684                NaN   \n",
       "2                                      NaN                NaN   \n",
       "3                               1513815670                NaN   \n",
       "4                               1513797243                NaN   \n",
       "\n",
       "  job_failed_at_time_epoch waiting_time_to_accept  \\\n",
       "0                      NaN                    NaN   \n",
       "1                      NaN                      3   \n",
       "2                      NaN                    NaN   \n",
       "3                      NaN                      3   \n",
       "4                      NaN                      5   \n",
       "\n",
       "  successful_job_completion_time failed_job_completion_time  \n",
       "0                            NaN                        NaN  \n",
       "1                            358                        NaN  \n",
       "2                            NaN                        NaN  \n",
       "3                           1169                        NaN  \n",
       "4                            537                        NaN  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert 'NA' into null value\n",
    "jobs = logs.replace(' NA', np.nan).copy()\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057 entries, 0 to 1056\n",
      "Data columns (total 18 columns):\n",
      "Log File                                    1057 non-null object\n",
      "state_accept_epoch                          539 non-null float64\n",
      "state_running_time                          538 non-null object\n",
      "state_running_epoch                         538 non-null object\n",
      "waiting_time_to_run                         538 non-null object\n",
      "spark_driver_start_time                     543 non-null object\n",
      "spark_driver_start_time_epoch               543 non-null object\n",
      "spark_driver_memory_MB                      543 non-null float64\n",
      "spark_executor_memory_MB                    543 non-null float64\n",
      "memoryStore_capacity_MB                     1031 non-null float64\n",
      "job_result                                  541 non-null object\n",
      "job_successfully_completed_at_time          511 non-null object\n",
      "job_successfully_completed_at_time_epoch    511 non-null object\n",
      "job_failed_at_time                          30 non-null object\n",
      "job_failed_at_time_epoch                    30 non-null object\n",
      "waiting_time_to_accept                      539 non-null object\n",
      "successful_job_completion_time              511 non-null object\n",
      "failed_job_completion_time                  26 non-null object\n",
      "dtypes: float64(4), object(14)\n",
      "memory usage: 148.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display info of jobs\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert epoch seconds to timestamp format\n",
    "import datetime\n",
    "for i in ['state_accept_epoch','state_running_epoch','spark_driver_start_time_epoch','job_successfully_completed_at_time_epoch','job_failed_at_time_epoch']:\n",
    "    p = i.replace(\"epoch\",\"datetime\")\n",
    "    jobs[p] = pd.to_datetime(jobs[i].astype('float'),unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Log File',\n",
       " 'state_accept_epoch',\n",
       " 'state_running_time',\n",
       " 'state_running_epoch',\n",
       " 'waiting_time_to_run',\n",
       " 'spark_driver_start_time',\n",
       " 'spark_driver_start_time_epoch',\n",
       " 'spark_driver_memory_MB',\n",
       " 'spark_executor_memory_MB',\n",
       " 'memoryStore_capacity_MB',\n",
       " 'job_result',\n",
       " 'job_successfully_completed_at_time',\n",
       " 'job_successfully_completed_at_time_epoch',\n",
       " 'job_failed_at_time',\n",
       " 'job_failed_at_time_epoch',\n",
       " 'waiting_time_to_accept',\n",
       " 'successful_job_completion_time',\n",
       " 'failed_job_completion_time',\n",
       " 'state_accept_datetime',\n",
       " 'state_running_datetime',\n",
       " 'spark_driver_start_time_datetime',\n",
       " 'job_successfully_completed_at_time_datetime',\n",
       " 'job_failed_at_time_datetime']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jobs.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arrange the order of columns\n",
    "jobs = jobs[['Log File',\n",
    " 'state_accept_datetime',\n",
    " 'state_accept_epoch',\n",
    " 'state_running_datetime',\n",
    " 'state_running_epoch',\n",
    " 'waiting_time_to_run',\n",
    " 'spark_driver_start_time_datetime',\n",
    " 'spark_driver_start_time_epoch',\n",
    " 'spark_driver_memory_MB',\n",
    " 'spark_executor_memory_MB',\n",
    " 'memoryStore_capacity_MB',\n",
    " 'job_result',\n",
    " 'job_successfully_completed_at_time_datetime',\n",
    " 'job_successfully_completed_at_time_epoch',\n",
    " 'job_failed_at_time_datetime',\n",
    " 'job_failed_at_time_epoch',\n",
    " 'waiting_time_to_accept',\n",
    " 'successful_job_completion_time',\n",
    " 'failed_job_completion_time'\n",
    " ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log File</th>\n",
       "      <th>state_accept_datetime</th>\n",
       "      <th>state_accept_epoch</th>\n",
       "      <th>state_running_datetime</th>\n",
       "      <th>state_running_epoch</th>\n",
       "      <th>waiting_time_to_run</th>\n",
       "      <th>spark_driver_start_time_datetime</th>\n",
       "      <th>spark_driver_start_time_epoch</th>\n",
       "      <th>spark_driver_memory_MB</th>\n",
       "      <th>spark_executor_memory_MB</th>\n",
       "      <th>memoryStore_capacity_MB</th>\n",
       "      <th>job_result</th>\n",
       "      <th>job_successfully_completed_at_time_datetime</th>\n",
       "      <th>job_successfully_completed_at_time_epoch</th>\n",
       "      <th>job_failed_at_time_datetime</th>\n",
       "      <th>job_failed_at_time_epoch</th>\n",
       "      <th>waiting_time_to_accept</th>\n",
       "      <th>successful_job_completion_time</th>\n",
       "      <th>failed_job_completion_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application_1513303661803_25646_asrd.cp.big.da...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application_1513303661803_23926_asrd.cp.big.da...</td>\n",
       "      <td>2017-12-20 17:52:00</td>\n",
       "      <td>1.513792e+09</td>\n",
       "      <td>2017-12-20 17:52:06</td>\n",
       "      <td>1513792326</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-12-20 17:51:57</td>\n",
       "      <td>1513792317</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>8601.6</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>2017-12-20 17:58:04</td>\n",
       "      <td>1513792684</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application_1513303661803_21767_asrd.cp.big.da...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application_1513303661803_24558_asrd.cp.big.da...</td>\n",
       "      <td>2017-12-21 00:01:36</td>\n",
       "      <td>1.513814e+09</td>\n",
       "      <td>2017-12-21 00:01:41</td>\n",
       "      <td>1513814501</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-12-21 00:01:33</td>\n",
       "      <td>1513814493</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>5632.0</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>2017-12-21 00:21:10</td>\n",
       "      <td>1513815670</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application_1513303661803_24282_asrd.cp.big.da...</td>\n",
       "      <td>2017-12-20 19:04:57</td>\n",
       "      <td>1.513797e+09</td>\n",
       "      <td>2017-12-20 19:05:06</td>\n",
       "      <td>1513796706</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-20 19:04:52</td>\n",
       "      <td>1513796692</td>\n",
       "      <td>12288.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>8601.6</td>\n",
       "      <td>Job completed successfully</td>\n",
       "      <td>2017-12-20 19:14:03</td>\n",
       "      <td>1513797243</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Log File state_accept_datetime  \\\n",
       "0  application_1513303661803_25646_asrd.cp.big.da...                   NaT   \n",
       "1  application_1513303661803_23926_asrd.cp.big.da...   2017-12-20 17:52:00   \n",
       "2  application_1513303661803_21767_asrd.cp.big.da...                   NaT   \n",
       "3  application_1513303661803_24558_asrd.cp.big.da...   2017-12-21 00:01:36   \n",
       "4  application_1513303661803_24282_asrd.cp.big.da...   2017-12-20 19:04:57   \n",
       "\n",
       "   state_accept_epoch state_running_datetime state_running_epoch  \\\n",
       "0                 NaN                    NaT                 NaN   \n",
       "1        1.513792e+09    2017-12-20 17:52:06          1513792326   \n",
       "2                 NaN                    NaT                 NaN   \n",
       "3        1.513814e+09    2017-12-21 00:01:41          1513814501   \n",
       "4        1.513797e+09    2017-12-20 19:05:06          1513796706   \n",
       "\n",
       "  waiting_time_to_run spark_driver_start_time_datetime  \\\n",
       "0                 NaN                              NaT   \n",
       "1                   6              2017-12-20 17:51:57   \n",
       "2                 NaN                              NaT   \n",
       "3                   5              2017-12-21 00:01:33   \n",
       "4                   9              2017-12-20 19:04:52   \n",
       "\n",
       "  spark_driver_start_time_epoch  spark_driver_memory_MB  \\\n",
       "0                           NaN                     NaN   \n",
       "1                    1513792317                 12288.0   \n",
       "2                           NaN                     NaN   \n",
       "3                    1513814493                  8192.0   \n",
       "4                    1513796692                 12288.0   \n",
       "\n",
       "   spark_executor_memory_MB  memoryStore_capacity_MB  \\\n",
       "0                       NaN                   1983.0   \n",
       "1                    6144.0                   8601.6   \n",
       "2                       NaN                    143.6   \n",
       "3                   15360.0                   5632.0   \n",
       "4                   16384.0                   8601.6   \n",
       "\n",
       "                    job_result job_successfully_completed_at_time_datetime  \\\n",
       "0                          NaN                                         NaT   \n",
       "1   Job completed successfully                         2017-12-20 17:58:04   \n",
       "2                          NaN                                         NaT   \n",
       "3   Job completed successfully                         2017-12-21 00:21:10   \n",
       "4   Job completed successfully                         2017-12-20 19:14:03   \n",
       "\n",
       "  job_successfully_completed_at_time_epoch job_failed_at_time_datetime  \\\n",
       "0                                      NaN                         NaT   \n",
       "1                               1513792684                         NaT   \n",
       "2                                      NaN                         NaT   \n",
       "3                               1513815670                         NaT   \n",
       "4                               1513797243                         NaT   \n",
       "\n",
       "  job_failed_at_time_epoch waiting_time_to_accept  \\\n",
       "0                      NaN                    NaN   \n",
       "1                      NaN                      3   \n",
       "2                      NaN                    NaN   \n",
       "3                      NaN                      3   \n",
       "4                      NaN                      5   \n",
       "\n",
       "  successful_job_completion_time failed_job_completion_time  \n",
       "0                            NaN                        NaN  \n",
       "1                            358                        NaN  \n",
       "2                            NaN                        NaN  \n",
       "3                           1169                        NaN  \n",
       "4                            537                        NaN  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057 entries, 0 to 1056\n",
      "Data columns (total 19 columns):\n",
      "Log File                                       1057 non-null object\n",
      "state_accept_datetime                          539 non-null datetime64[ns]\n",
      "state_accept_epoch                             539 non-null float64\n",
      "state_running_datetime                         538 non-null datetime64[ns]\n",
      "state_running_epoch                            538 non-null object\n",
      "waiting_time_to_run                            538 non-null object\n",
      "spark_driver_start_time_datetime               543 non-null datetime64[ns]\n",
      "spark_driver_start_time_epoch                  543 non-null object\n",
      "spark_driver_memory_MB                         543 non-null float64\n",
      "spark_executor_memory_MB                       543 non-null float64\n",
      "memoryStore_capacity_MB                        1031 non-null float64\n",
      "job_result                                     541 non-null object\n",
      "job_successfully_completed_at_time_datetime    511 non-null datetime64[ns]\n",
      "job_successfully_completed_at_time_epoch       511 non-null object\n",
      "job_failed_at_time_datetime                    30 non-null datetime64[ns]\n",
      "job_failed_at_time_epoch                       30 non-null object\n",
      "waiting_time_to_accept                         539 non-null object\n",
      "successful_job_completion_time                 511 non-null object\n",
      "failed_job_completion_time                     26 non-null object\n",
      "dtypes: datetime64[ns](5), float64(4), object(10)\n",
      "memory usage: 157.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# final check\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "jobs.head()\n",
    "jobs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Export a cleaned csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs.to_csv('C:/Users/Mengyu/Desktop/study/Auto Desk/log_extraction/Clean_Key_Metrics_v4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
